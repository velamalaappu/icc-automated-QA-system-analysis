{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Automated Question Answer System.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "15G31wsy4rOpn3q24H-RAPnBjQBOhlzpn",
      "authorship_tag": "ABX9TyPE0pxMaee+Blj2NRYZ1M+g",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/velamalaappu/icc-automated-QA-system-analysis/blob/main/Automated_Question_Answer_System.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Automated Question Answer System**"
      ],
      "metadata": {
        "id": "GIlcK5IjSqWH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Project Introduction**"
      ],
      "metadata": {
        "id": "D7KsTQd-TO5X"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Indian education landscape has been undergoing rapid changes for the past 10 years owing to the advancement of web-based learning services, specifically, eLearning platforms.\n",
        "\n",
        "Most online education institutes today treat all students in the same class/batch/cohort (referred to as “group” hereinafter) the same. Institutional uniformity works quite well for machines but humans are made up of different and often contradictory components!\n",
        "\n",
        "We believe that the model of allowing all students to learn at the same pace with the same level of interest is quite detrimental to the quality of education. This model is testing the capabilities of students by forcing them to work together in groups at the same pace, regardless of each individual's\n",
        "ability and the interests of the work.\n",
        "\n",
        "The reality could not be farther from the truth. The reason we see a wide variation in the group performance is owing to this thought process.\n",
        "\n",
        "In a system based on Competency Based Learning (referred to as “CBL” going forward), the group is accepted as a set of diverse individuals who may come with some common traits but also recognizes their different educational backgrounds, life & work experiences and learning styles.\n",
        "\n",
        "Competency-based learning is an approach to education that focuses on the student’s demonstration of desired learning outcomes as central to the learning process. A key characteristic of competency-based learning is its focus on mastery. In other learning models, students are exposed to content–whether skills or concepts–over time, and success is measured on a summative basis. In a\n",
        "competency-based learning system, students are not allowed to continue until they have demonstrated mastery of the identified competencies (i.e., the desired learning outcomes to be demonstrated).\n",
        "\n",
        "It is quite common to see students get stuck, fall behind, give up & in extreme cases – drop out of the program in the traditional model of education. A standard experience for a student in this model is “failing” and then having to repeat the class/subject/year till they are able to achieve a passing grade.\n",
        "This causes the student to lose interest in addition to social embarrassment. The result is a student who is now trying to “pass” by rote memorization and doing the bare minimum for the passing.\n",
        "\n",
        "While assessments based on rubrics are a cornerstone for the CBL system as well – they serve the purpose of reinforcing the concepts, and to show the student & the instructor(s) how well understood are each of the concepts and their application; rather than making just a judgment of passing and failing.\n",
        "\n",
        "In this light, to be able to cater to a large pool of students to enable seamless learning, we envision an automated doubt resolution system. In the era of advancing AI technology, most of the doubts can be resolved via deep learning techniques. The AI system in place can understand the context of the\n",
        "question and can provide relevant answers to the questions.\n"
      ],
      "metadata": {
        "id": "V3F9pK9LTS0L"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Problem Statement**"
      ],
      "metadata": {
        "id": "zwDmMCZuUu2w"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will solve the above-mentioned challenge by applying deep learning algorithms to textual data.\n",
        "The solution to this problem can be obtained through Extractive Question Answering wherein we can extract an answer from a text given the question.\n"
      ],
      "metadata": {
        "id": "Jri11se1U3Ue"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Question Answering Bot**"
      ],
      "metadata": {
        "id": "8y16lcYMSjWp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Loading the Data**"
      ],
      "metadata": {
        "id": "Jdiypr2WSu5B"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I work with the Babi Data Set from Facebook Research.\n",
        "\n",
        "Full Details: https://research.fb.com/downloads/babi/\n",
        "\n",
        "Jason Weston, Antoine Bordes, Sumit Chopra, Tomas Mikolov, Alexander M. Rush, \"Towards AI-Complete Question Answering: A Set of Prerequisite Toy Tasks\", http://arxiv.org/abs/1502.05698"
      ],
      "metadata": {
        "id": "7f0VOm-__C3A"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NlZs_s5u9uOu"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"/content/drive/MyDrive/Colab Notebooks/question answer system/train_qa.txt\", \"rb\") as fp:   # Unpickling, read-binary\n",
        "    train_data =  pickle.load(fp)"
      ],
      "metadata": {
        "id": "aziroa0a95vB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"/content/drive/MyDrive/Colab Notebooks/question answer system/test_qa.txt\", \"rb\") as fp:   # Unpickling\n",
        "    test_data =  pickle.load(fp)"
      ],
      "metadata": {
        "id": "UsqnZlJQ-P1z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Exploring the Format of the Data**"
      ],
      "metadata": {
        "id": "p4k-qt6ACt7D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "type(test_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LJVRN61m-caS",
        "outputId": "18d23576-0ab2-4a6a-b2fc-66b1effdc379"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "list"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(train_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GsVjz6Oz-oFD",
        "outputId": "b85d79dc-3f60-4746-e9d8-c5d423d2b447"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "list"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(test_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SZnFkQgJ-se6",
        "outputId": "a3b00e01-0878-47a6-9fe6-5eda088c0895"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1000"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fXfjIQmg-wna",
        "outputId": "5eef87c8-c720-4277-9481-d52d4b2e3eda"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10000"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data[50]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zl34mOnL-4iC",
        "outputId": "a5b25bd4-f0fa-488e-e748-c37e91e71b3d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(['Mary',\n",
              "  'went',\n",
              "  'back',\n",
              "  'to',\n",
              "  'the',\n",
              "  'bathroom',\n",
              "  '.',\n",
              "  'Daniel',\n",
              "  'went',\n",
              "  'to',\n",
              "  'the',\n",
              "  'office',\n",
              "  '.'],\n",
              " ['Is', 'Mary', 'in', 'the', 'bathroom', '?'],\n",
              " 'yes')"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PUvMncLO-6uD",
        "outputId": "1973ee10-e7d3-485d-f1e8-410b30902d51"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(['Mary',\n",
              "  'moved',\n",
              "  'to',\n",
              "  'the',\n",
              "  'bathroom',\n",
              "  '.',\n",
              "  'Sandra',\n",
              "  'journeyed',\n",
              "  'to',\n",
              "  'the',\n",
              "  'bedroom',\n",
              "  '.'],\n",
              " ['Is', 'Sandra', 'in', 'the', 'hallway', '?'],\n",
              " 'no')"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text=''\n",
        "print('Story:')\n",
        "for sent in train_data[99]:\n",
        "    if sent!='yes' and sent!='no':\n",
        "        for word in sent:\n",
        "            if (word!='.'):\n",
        "                if (word!='?'):\n",
        "                    text+= word + ' '\n",
        "                else:\n",
        "                    print()\n",
        "                    print('Question:', text[:-1]+word)\n",
        "                    print()\n",
        "            else:\n",
        "                print(text[:-1]+word)\n",
        "                text=''\n",
        "    else:\n",
        "        print('Answer:', sent)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qlP2itX5-_z_",
        "outputId": "8d41e82f-53f3-4769-ce64-0c7e61d1324a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Story:\n",
            "Daniel grabbed the apple there.\n",
            "Daniel went to the bedroom.\n",
            "John moved to the garden.\n",
            "Sandra journeyed to the office.\n",
            "Daniel put down the apple.\n",
            "Mary went to the bedroom.\n",
            "Mary grabbed the apple there.\n",
            "Sandra went back to the garden.\n",
            "Mary went to the kitchen.\n",
            "Daniel went to the office.\n",
            "\n",
            "Question: Is Mary in the garden?\n",
            "\n",
            "Answer: no\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "' '.join(train_data[0][0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "lxUPcMBQ_Ij1",
        "outputId": "10268112-a33f-4d78-d5fb-cd0e7d649443"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Mary moved to the bathroom . Sandra journeyed to the bedroom .'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "' '.join(train_data[0][1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "rH88MzM9_OIs",
        "outputId": "7168ba57-66db-4c33-baab-40eb3a44362a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Is Sandra in the hallway ?'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data[0][2]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "HzZhimi7_Z_K",
        "outputId": "7c6827c5-71bd-4767-92d5-d2e2e5f1ed1b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'no'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Setting up Vocabulary of All Words**"
      ],
      "metadata": {
        "id": "i2X0by44DFR4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a set that holds the vocab words\n",
        "vocab = set()"
      ],
      "metadata": {
        "id": "YsNWn2p8_kMN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_data = test_data + train_data"
      ],
      "metadata": {
        "id": "3wHE1BQ6_mEA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(all_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "878dOVkD_q_y",
        "outputId": "f20b1ef5-440a-43ef-cf6a-a8ce7bc83e02"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "11000"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "set(train_data[0][0]) # story component"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vvCRE_NE_wYe",
        "outputId": "b8ce6d6f-5ac2-4147-828e-7714ab436419"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'.',\n",
              " 'Mary',\n",
              " 'Sandra',\n",
              " 'bathroom',\n",
              " 'bedroom',\n",
              " 'journeyed',\n",
              " 'moved',\n",
              " 'the',\n",
              " 'to'}"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for story, question , answer in all_data:\n",
        "    # In case you don't know what a union of sets is:\n",
        "    # https://www.programiz.com/python-programming/methods/set/union\n",
        "    vocab = vocab.union(set(story))\n",
        "    vocab = vocab.union(set(question))"
      ],
      "metadata": {
        "id": "On6Jc4r9_1vz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "adding the answer possibilities"
      ],
      "metadata": {
        "id": "MmbDfAFZDRvh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vocab.add('no')\n",
        "vocab.add('yes')"
      ],
      "metadata": {
        "id": "JsFH1aRL_-4B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Zv5VatJADDV",
        "outputId": "5fc41cde-0dab-4b9e-8e56-41fe26b418eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'.',\n",
              " '?',\n",
              " 'Daniel',\n",
              " 'Is',\n",
              " 'John',\n",
              " 'Mary',\n",
              " 'Sandra',\n",
              " 'apple',\n",
              " 'back',\n",
              " 'bathroom',\n",
              " 'bedroom',\n",
              " 'discarded',\n",
              " 'down',\n",
              " 'dropped',\n",
              " 'football',\n",
              " 'garden',\n",
              " 'got',\n",
              " 'grabbed',\n",
              " 'hallway',\n",
              " 'in',\n",
              " 'journeyed',\n",
              " 'kitchen',\n",
              " 'left',\n",
              " 'milk',\n",
              " 'moved',\n",
              " 'no',\n",
              " 'office',\n",
              " 'picked',\n",
              " 'put',\n",
              " 'the',\n",
              " 'there',\n",
              " 'to',\n",
              " 'took',\n",
              " 'travelled',\n",
              " 'up',\n",
              " 'went',\n",
              " 'yes'}"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_len = len(vocab) + 1 "
      ],
      "metadata": {
        "id": "_H1Z7X0MAIRg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_len"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W3dAi_nHAQLM",
        "outputId": "fcfa207c-9d54-4d72-e269-5be328e745e6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "38"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_story_len = max([len(data[0]) for data in all_data])\n"
      ],
      "metadata": {
        "id": "Ix-4i3frAUbx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_story_len"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IX4tUiq2AZlB",
        "outputId": "10f61f9f-6e36-4425-97d1-fae5a630daff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "156"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_question_len = max([len(data[1]) for data in all_data])"
      ],
      "metadata": {
        "id": "83_54HbkAddu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_question_len"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FK7XcyH8AiED",
        "outputId": "6dd1c3df-7bde-4dc0-81fa-1f0659f6bdb7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Vectorizing the Data**"
      ],
      "metadata": {
        "id": "tsHckLBoDjpl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Reserve 0 for pad_sequences\n",
        "vocab_size = len(vocab) + 1"
      ],
      "metadata": {
        "id": "XJLXfDazA1Y8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer"
      ],
      "metadata": {
        "id": "x7dz-jpdA4DH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# integer encode sequences of words\n",
        "tokenizer = Tokenizer(filters=[])   # provide empty list for filter out\n",
        "tokenizer.fit_on_texts(vocab)"
      ],
      "metadata": {
        "id": "2J9sTBBiA3yD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.word_index"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e_udSuOIBDkN",
        "outputId": "a92664d8-b5b2-422e-d603-57eae4320620"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'.': 14,\n",
              " '?': 10,\n",
              " 'apple': 9,\n",
              " 'back': 36,\n",
              " 'bathroom': 33,\n",
              " 'bedroom': 22,\n",
              " 'daniel': 3,\n",
              " 'discarded': 15,\n",
              " 'down': 34,\n",
              " 'dropped': 19,\n",
              " 'football': 8,\n",
              " 'garden': 24,\n",
              " 'got': 25,\n",
              " 'grabbed': 20,\n",
              " 'hallway': 12,\n",
              " 'in': 2,\n",
              " 'is': 5,\n",
              " 'john': 4,\n",
              " 'journeyed': 27,\n",
              " 'kitchen': 29,\n",
              " 'left': 11,\n",
              " 'mary': 13,\n",
              " 'milk': 1,\n",
              " 'moved': 21,\n",
              " 'no': 7,\n",
              " 'office': 16,\n",
              " 'picked': 17,\n",
              " 'put': 28,\n",
              " 'sandra': 6,\n",
              " 'the': 26,\n",
              " 'there': 31,\n",
              " 'to': 37,\n",
              " 'took': 32,\n",
              " 'travelled': 18,\n",
              " 'up': 30,\n",
              " 'went': 23,\n",
              " 'yes': 35}"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_story_text = []\n",
        "train_question_text = []\n",
        "train_answers = []\n",
        "\n",
        "for story,question,answer in train_data:\n",
        "    train_story_text.append(story)\n",
        "    train_question_text.append(question)"
      ],
      "metadata": {
        "id": "X6hmfv8CBISF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_story_seq = tokenizer.texts_to_sequences(train_story_text)"
      ],
      "metadata": {
        "id": "yuTuzHJZByM7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_story_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ht_VjN9B2KU",
        "outputId": "d7e48e32-2e09-4def-ad06-dae0b57c8e9c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10000"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_story_seq)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ttn5K1KB6Sm",
        "outputId": "3d5b16bf-3fc2-4870-ec7c-20fc3e0f21eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10000"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# word_index = tokenizer.word_index"
      ],
      "metadata": {
        "id": "nYHaF3-tCAfm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Functionalize Vectorization**"
      ],
      "metadata": {
        "id": "xIAGJwbUD05C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def vectorize_stories(data, word_index=tokenizer.word_index, max_story_len=max_story_len,max_question_len=max_question_len):\n",
        "    '''\n",
        "    INPUT: \n",
        "    \n",
        "    data: consisting of Stories,Queries,and Answers\n",
        "    word_index: word index dictionary from tokenizer\n",
        "    max_story_len: the length of the longest story (used for pad_sequences function)\n",
        "    max_question_len: length of the longest question (used for pad_sequences function)\n",
        "\n",
        "\n",
        "    OUTPUT:\n",
        "    \n",
        "    Vectorizes the stories,questions, and answers into padded sequences. We first loop for every story, query , and\n",
        "    answer in the data. Then we convert the raw words to an word index value. Then we append each set to their appropriate\n",
        "    output list. Then once we have converted the words to numbers, we pad the sequences so they are all of equal length.\n",
        "    \n",
        "    Returns this in the form of a tuple (X,Xq,Y) (padded based on max lengths)\n",
        "    '''\n",
        "    \n",
        "    \n",
        "    # X = STORIES\n",
        "    X = []\n",
        "    # Xq = QUERY/QUESTION\n",
        "    Xq = []\n",
        "    # Y = CORRECT ANSWER\n",
        "    Y = []\n",
        "    \n",
        "    \n",
        "    for story, query, answer in data:\n",
        "        \n",
        "        # Grab the word index for every word in story\n",
        "        x = [word_index[word.lower()] for word in story]\n",
        "        # Grab the word index for every word in query\n",
        "        xq = [word_index[word.lower()] for word in query]\n",
        "        \n",
        "        # Grab the Answers (either Yes/No so we don't need to use list comprehension here)\n",
        "        # Index 0 is reserved so we're going to use + 1\n",
        "        y = np.zeros(vocab_size)  # this includes +1 for padding\n",
        "        \n",
        "        # Now that y is all zeros and we know its just Yes/No , we can use numpy logic to create this assignment\n",
        "        y[word_index[answer]] = 1\n",
        "        \n",
        "        # Append each set of story,query, and answer to their respective holding lists\n",
        "        X.append(x)\n",
        "        Xq.append(xq)\n",
        "        Y.append(y)\n",
        "        \n",
        "    # Finally, pad the sequences based on their max length so the RNN can be trained on uniformly long sequences.\n",
        "        \n",
        "    # RETURN TUPLE FOR UNPACKING\n",
        "    return (pad_sequences(X, maxlen=max_story_len),pad_sequences(Xq, maxlen=max_question_len), np.array(Y))"
      ],
      "metadata": {
        "id": "JVEuTLFvCD8T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs_train, queries_train, answers_train = vectorize_stories(train_data)"
      ],
      "metadata": {
        "id": "jflsjo1OCNG6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs_test, queries_test, answers_test = vectorize_stories(test_data)"
      ],
      "metadata": {
        "id": "bkr7A5ImCRRM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# padding mode 'pre'\n",
        "inputs_test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ByIWboJVCV1N",
        "outputId": "f64f82fe-9966-4cf5-e33d-0cdc8cfd097e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0,  0,  0, ..., 26, 22, 14],\n",
              "       [ 0,  0,  0, ..., 26, 24, 14],\n",
              "       [ 0,  0,  0, ..., 26, 24, 14],\n",
              "       ...,\n",
              "       [ 0,  0,  0, ..., 26,  9, 14],\n",
              "       [ 0,  0,  0, ..., 26, 24, 14],\n",
              "       [ 0,  0,  0, ...,  9, 31, 14]], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "queries_test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7xfX_jQcCa5J",
        "outputId": "8887a2c8-9532-41ae-8967-ba66a65d322c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 5,  4,  2, 26, 29, 10],\n",
              "       [ 5,  4,  2, 26, 29, 10],\n",
              "       [ 5,  4,  2, 26, 24, 10],\n",
              "       ...,\n",
              "       [ 5, 13,  2, 26, 22, 10],\n",
              "       [ 5,  6,  2, 26, 24, 10],\n",
              "       [ 5, 13,  2, 26, 24, 10]], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# one-hot vectors of size V vocabulary for Yes / No\n",
        "answers_test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "35CX6TKdCfsY",
        "outputId": "99b38fc5-9248-4a9e-b26c-f66d42fe8c26"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 1., 0., 0.],\n",
              "       ...,\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 1., 0., 0.],\n",
              "       [0., 0., 0., ..., 1., 0., 0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Equal proportion of Yes / No answers\n",
        "sum(answers_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NPgrRraJCtPq",
        "outputId": "a45889ea-2c77-42ca-c69a-94043bd57cd9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([  0.,   0.,   0.,   0.,   0.,   0.,   0., 503.,   0.,   0.,   0.,\n",
              "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
              "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
              "         0.,   0., 497.,   0.,   0.])"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.word_index['yes']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NqErrS7zCxJK",
        "outputId": "e1e5f753-9016-405f-f4e3-f0fc5bc707d5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "35"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.word_index['no']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "12afSL-ZC5X2",
        "outputId": "bdd70b1b-a034-4502-90c7-d7f4ca433a46"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Creating the Model**"
      ],
      "metadata": {
        "id": "kTvfYv2zEKX8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.layers import Embedding\n",
        "from tensorflow.keras.layers import Input, Activation, Dense, Permute, Dropout\n",
        "from tensorflow.keras.layers import add, dot, concatenate\n",
        "from tensorflow.keras.layers import LSTM\n",
        "from tensorflow.keras.optimizers import RMSprop"
      ],
      "metadata": {
        "id": "LY-6XN__C_xm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Placeholders for Inputs**"
      ],
      "metadata": {
        "id": "A_sAamTXESH6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Recall we technically have two inputs, stories and questions. So we need to use placeholders. Input() is used to instantiate a Keras tensor."
      ],
      "metadata": {
        "id": "Wljq7WdSEak8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_sequence = Input((max_story_len,))\n",
        "question = Input((max_question_len,))"
      ],
      "metadata": {
        "id": "6RSOkQ_sDFZx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Building the Networks**"
      ],
      "metadata": {
        "id": "GSpqkOh9Ei1c"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Encoders**"
      ],
      "metadata": {
        "id": "gN8LaMsPErYq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Input Encoder m**"
      ],
      "metadata": {
        "id": "7JtcwpGhEwpr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_dim = 128\n",
        "\n",
        "# Input gets embedded to a sequence of vectors\n",
        "input_encoder_m = Sequential()\n",
        "input_encoder_m.add(Embedding(input_dim=vocab_size,output_dim= embedding_dim))\n",
        "input_encoder_m.add(Dropout(0.3))\n",
        "\n",
        "# This encoder will output:\n",
        "# (samples, story_maxlen, embedding_dim)"
      ],
      "metadata": {
        "id": "cZ26adFUDJzc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Input Encoder c**"
      ],
      "metadata": {
        "id": "HRDKM_QnE8mk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# embed the input into a sequence of vectors of size query_maxlen\n",
        "input_encoder_c = Sequential()\n",
        "input_encoder_c.add(Embedding(input_dim=vocab_size,output_dim=max_question_len))\n",
        "input_encoder_c.add(Dropout(0.3))\n",
        "# output: (samples, story_maxlen, query_maxlen)"
      ],
      "metadata": {
        "id": "zxxLfGQaDQOz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Question Encoder**"
      ],
      "metadata": {
        "id": "dUvqWwQVFD83"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# embed the question into a sequence of vectors\n",
        "question_encoder = Sequential()\n",
        "question_encoder.add(Embedding(input_dim=vocab_size,\n",
        "                               output_dim=embedding_dim,\n",
        "                               input_length=max_question_len))\n",
        "question_encoder.add(Dropout(0.3))\n",
        "# output: (samples, query_maxlen, embedding_dim)"
      ],
      "metadata": {
        "id": "cu6XKvg3DVEd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Encode the Sequences**"
      ],
      "metadata": {
        "id": "ZfseYd6FFLo3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# encode input sequence and questions (which are indices) to sequences of dense vectors\n",
        "input_encoded_m = input_encoder_m(input_sequence)\n",
        "input_encoded_c = input_encoder_c(input_sequence)\n",
        "question_encoded = question_encoder(question)"
      ],
      "metadata": {
        "id": "LXLVkSiQDanx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Use dot product to compute the match between first input vector seq and the query"
      ],
      "metadata": {
        "id": "qtaPXrDwFUkp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# shape: `(samples, story_maxlen, query_maxlen)`\n",
        "match = dot([input_encoded_m, question_encoded], axes=(2, 2))\n",
        "match = Activation('softmax')(match)"
      ],
      "metadata": {
        "id": "UW1tSu2NDgSc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Add this match matrix with the second input vector sequence"
      ],
      "metadata": {
        "id": "8EN8OyllFZmj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# add the match matrix with the second input vector sequence\n",
        "response = add([match, input_encoded_c])  # (samples, story_maxlen, query_maxlen)\n",
        "response = Permute((2, 1))(response)  # (samples, query_maxlen, story_maxlen)"
      ],
      "metadata": {
        "id": "wkrPWcFeDlVG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Concatenate**"
      ],
      "metadata": {
        "id": "S4cajs9ZFiuh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# concatenate the match matrix with the question vector sequence\n",
        "# (samples, query_maxlen, story_maxlen + embedding_dim)\n",
        "answer = concatenate([response, question_encoded])"
      ],
      "metadata": {
        "id": "-0jt851BDpCO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "answer"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0wdCA39tDvZ3",
        "outputId": "78e9e49c-3f59-4605-d51f-a4ec10c67de6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<KerasTensor: shape=(None, 6, 284) dtype=float32 (created by layer 'concatenate')>"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Reduce with RNN (LSTM)\n",
        "answer = LSTM(32)(answer)  # shape (samples, 32)"
      ],
      "metadata": {
        "id": "wWMqtSuIDyuz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Regularization with Dropout\n",
        "answer = Dropout(0.5)(answer)\n",
        "answer = Dense(vocab_size)(answer)  # (samples, vocab_size)"
      ],
      "metadata": {
        "id": "zYS91LbID3l1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# we output a probability distribution over the vocabulary\n",
        "answer = Activation('softmax')(answer)\n",
        "\n",
        "# build the final model\n",
        "model = Model([input_sequence, question], answer)\n",
        "optimizer = RMSprop(learning_rate=0.01)\n",
        "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "l9FbVe6OD7hM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4bMkJ6_-D_5U",
        "outputId": "aa7cc3eb-ac16-48dc-b2e7-97b5f63e0545"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 156)]        0           []                               \n",
            "                                                                                                  \n",
            " input_2 (InputLayer)           [(None, 6)]          0           []                               \n",
            "                                                                                                  \n",
            " sequential (Sequential)        (None, None, 128)    4864        ['input_1[0][0]']                \n",
            "                                                                                                  \n",
            " sequential_2 (Sequential)      (None, 6, 128)       4864        ['input_2[0][0]']                \n",
            "                                                                                                  \n",
            " dot (Dot)                      (None, 156, 6)       0           ['sequential[0][0]',             \n",
            "                                                                  'sequential_2[0][0]']           \n",
            "                                                                                                  \n",
            " activation (Activation)        (None, 156, 6)       0           ['dot[0][0]']                    \n",
            "                                                                                                  \n",
            " sequential_1 (Sequential)      (None, None, 6)      228         ['input_1[0][0]']                \n",
            "                                                                                                  \n",
            " add (Add)                      (None, 156, 6)       0           ['activation[0][0]',             \n",
            "                                                                  'sequential_1[0][0]']           \n",
            "                                                                                                  \n",
            " permute (Permute)              (None, 6, 156)       0           ['add[0][0]']                    \n",
            "                                                                                                  \n",
            " concatenate (Concatenate)      (None, 6, 284)       0           ['permute[0][0]',                \n",
            "                                                                  'sequential_2[0][0]']           \n",
            "                                                                                                  \n",
            " lstm (LSTM)                    (None, 32)           40576       ['concatenate[0][0]']            \n",
            "                                                                                                  \n",
            " dropout_3 (Dropout)            (None, 32)           0           ['lstm[0][0]']                   \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, 38)           1254        ['dropout_3[0][0]']              \n",
            "                                                                                                  \n",
            " activation_1 (Activation)      (None, 38)           0           ['dense[0][0]']                  \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 51,786\n",
            "Trainable params: 51,786\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping, ModelCheckpoint, LearningRateScheduler\n",
        "\n",
        "initial_learning_rate = 0.01\n",
        "epochs = 120\n",
        "decay = initial_learning_rate / epochs\n",
        "\n",
        "def lr_step_decay(epoch, lr):\n",
        "    drop_rate = 0.5\n",
        "    epochs_drop = 20\n",
        "    return initial_learning_rate * math.pow(drop_rate, math.floor(epoch/epochs_drop))\n",
        "\n",
        "learning_rate = LearningRateScheduler(lr_step_decay, verbose=1)\n",
        "\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.66, patience=5, min_lr=0.0001, verbose=1) "
      ],
      "metadata": {
        "id": "kSJ4FKTjEKR0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train\n",
        "history = model.fit([inputs_train, queries_train], answers_train,batch_size=256,epochs=120,validation_data=([inputs_test, queries_test], answers_test)) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "17EoSOqDEMFw",
        "outputId": "391880e6-d3be-48ea-ab0e-7e927a4eba10"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/120\n",
            "40/40 [==============================] - 9s 146ms/step - loss: 0.8701 - accuracy: 0.4837 - val_loss: 0.7345 - val_accuracy: 0.5030\n",
            "Epoch 2/120\n",
            "40/40 [==============================] - 5s 126ms/step - loss: 0.7070 - accuracy: 0.5093 - val_loss: 0.7714 - val_accuracy: 0.5030\n",
            "Epoch 3/120\n",
            "40/40 [==============================] - 5s 128ms/step - loss: 0.7030 - accuracy: 0.5030 - val_loss: 0.7439 - val_accuracy: 0.4970\n",
            "Epoch 4/120\n",
            "40/40 [==============================] - 5s 127ms/step - loss: 0.7014 - accuracy: 0.4961 - val_loss: 0.6941 - val_accuracy: 0.5030\n",
            "Epoch 5/120\n",
            "40/40 [==============================] - 5s 127ms/step - loss: 0.6986 - accuracy: 0.4907 - val_loss: 0.6937 - val_accuracy: 0.4970\n",
            "Epoch 6/120\n",
            "40/40 [==============================] - 5s 122ms/step - loss: 0.6871 - accuracy: 0.5327 - val_loss: 0.6703 - val_accuracy: 0.5480\n",
            "Epoch 7/120\n",
            "40/40 [==============================] - 5s 131ms/step - loss: 0.5661 - accuracy: 0.7195 - val_loss: 0.5962 - val_accuracy: 0.7060\n",
            "Epoch 8/120\n",
            "40/40 [==============================] - 5s 125ms/step - loss: 0.4449 - accuracy: 0.8088 - val_loss: 0.3993 - val_accuracy: 0.8280\n",
            "Epoch 9/120\n",
            "40/40 [==============================] - 5s 125ms/step - loss: 0.3947 - accuracy: 0.8317 - val_loss: 0.4580 - val_accuracy: 0.7940\n",
            "Epoch 10/120\n",
            "40/40 [==============================] - 5s 123ms/step - loss: 0.3608 - accuracy: 0.8455 - val_loss: 0.5061 - val_accuracy: 0.7780\n",
            "Epoch 11/120\n",
            "40/40 [==============================] - 5s 122ms/step - loss: 0.3538 - accuracy: 0.8463 - val_loss: 0.4483 - val_accuracy: 0.8150\n",
            "Epoch 12/120\n",
            "40/40 [==============================] - 5s 125ms/step - loss: 0.3312 - accuracy: 0.8548 - val_loss: 0.3612 - val_accuracy: 0.8180\n",
            "Epoch 13/120\n",
            "40/40 [==============================] - 5s 126ms/step - loss: 0.3164 - accuracy: 0.8610 - val_loss: 0.3836 - val_accuracy: 0.8360\n",
            "Epoch 14/120\n",
            "40/40 [==============================] - 5s 122ms/step - loss: 0.3137 - accuracy: 0.8574 - val_loss: 0.3389 - val_accuracy: 0.8440\n",
            "Epoch 15/120\n",
            "40/40 [==============================] - 5s 129ms/step - loss: 0.3050 - accuracy: 0.8612 - val_loss: 0.4153 - val_accuracy: 0.7990\n",
            "Epoch 16/120\n",
            "40/40 [==============================] - 5s 126ms/step - loss: 0.3043 - accuracy: 0.8623 - val_loss: 0.3503 - val_accuracy: 0.8300\n",
            "Epoch 17/120\n",
            "40/40 [==============================] - 5s 121ms/step - loss: 0.2968 - accuracy: 0.8658 - val_loss: 0.3675 - val_accuracy: 0.8250\n",
            "Epoch 18/120\n",
            "40/40 [==============================] - 5s 118ms/step - loss: 0.2993 - accuracy: 0.8641 - val_loss: 0.3522 - val_accuracy: 0.8310\n",
            "Epoch 19/120\n",
            "40/40 [==============================] - 5s 130ms/step - loss: 0.2933 - accuracy: 0.8642 - val_loss: 0.3657 - val_accuracy: 0.8430\n",
            "Epoch 20/120\n",
            "40/40 [==============================] - 5s 126ms/step - loss: 0.2935 - accuracy: 0.8640 - val_loss: 0.3334 - val_accuracy: 0.8330\n",
            "Epoch 21/120\n",
            "40/40 [==============================] - 6s 137ms/step - loss: 0.2891 - accuracy: 0.8684 - val_loss: 0.4030 - val_accuracy: 0.8080\n",
            "Epoch 22/120\n",
            "40/40 [==============================] - 5s 118ms/step - loss: 0.2878 - accuracy: 0.8704 - val_loss: 0.3651 - val_accuracy: 0.8340\n",
            "Epoch 23/120\n",
            "40/40 [==============================] - 5s 123ms/step - loss: 0.2847 - accuracy: 0.8691 - val_loss: 0.3701 - val_accuracy: 0.8430\n",
            "Epoch 24/120\n",
            "40/40 [==============================] - 5s 128ms/step - loss: 0.2813 - accuracy: 0.8715 - val_loss: 0.4052 - val_accuracy: 0.8310\n",
            "Epoch 25/120\n",
            "40/40 [==============================] - 5s 124ms/step - loss: 0.2814 - accuracy: 0.8709 - val_loss: 0.3654 - val_accuracy: 0.8400\n",
            "Epoch 26/120\n",
            "40/40 [==============================] - 9s 221ms/step - loss: 0.2796 - accuracy: 0.8724 - val_loss: 0.3581 - val_accuracy: 0.8310\n",
            "Epoch 27/120\n",
            "40/40 [==============================] - 6s 154ms/step - loss: 0.2756 - accuracy: 0.8738 - val_loss: 0.4089 - val_accuracy: 0.8340\n",
            "Epoch 28/120\n",
            "40/40 [==============================] - 5s 121ms/step - loss: 0.2780 - accuracy: 0.8738 - val_loss: 0.3539 - val_accuracy: 0.8350\n",
            "Epoch 29/120\n",
            "40/40 [==============================] - 5s 123ms/step - loss: 0.2785 - accuracy: 0.8731 - val_loss: 0.3523 - val_accuracy: 0.8430\n",
            "Epoch 30/120\n",
            "40/40 [==============================] - 5s 129ms/step - loss: 0.2706 - accuracy: 0.8758 - val_loss: 0.3738 - val_accuracy: 0.8280\n",
            "Epoch 31/120\n",
            "40/40 [==============================] - 5s 127ms/step - loss: 0.2707 - accuracy: 0.8761 - val_loss: 0.3764 - val_accuracy: 0.8380\n",
            "Epoch 32/120\n",
            "40/40 [==============================] - 5s 127ms/step - loss: 0.2671 - accuracy: 0.8798 - val_loss: 0.5053 - val_accuracy: 0.8210\n",
            "Epoch 33/120\n",
            "40/40 [==============================] - 5s 124ms/step - loss: 0.2650 - accuracy: 0.8799 - val_loss: 0.3935 - val_accuracy: 0.8340\n",
            "Epoch 34/120\n",
            "40/40 [==============================] - 5s 128ms/step - loss: 0.2610 - accuracy: 0.8802 - val_loss: 0.4188 - val_accuracy: 0.8370\n",
            "Epoch 35/120\n",
            "40/40 [==============================] - 5s 125ms/step - loss: 0.2605 - accuracy: 0.8799 - val_loss: 0.4743 - val_accuracy: 0.8290\n",
            "Epoch 36/120\n",
            "40/40 [==============================] - 5s 119ms/step - loss: 0.2664 - accuracy: 0.8800 - val_loss: 0.3877 - val_accuracy: 0.8340\n",
            "Epoch 37/120\n",
            "40/40 [==============================] - 5s 126ms/step - loss: 0.2561 - accuracy: 0.8835 - val_loss: 0.3690 - val_accuracy: 0.8350\n",
            "Epoch 38/120\n",
            "40/40 [==============================] - 5s 130ms/step - loss: 0.2527 - accuracy: 0.8873 - val_loss: 0.4060 - val_accuracy: 0.8130\n",
            "Epoch 39/120\n",
            "40/40 [==============================] - 5s 125ms/step - loss: 0.2487 - accuracy: 0.8894 - val_loss: 0.3729 - val_accuracy: 0.8330\n",
            "Epoch 40/120\n",
            "40/40 [==============================] - 5s 125ms/step - loss: 0.2481 - accuracy: 0.8876 - val_loss: 0.3850 - val_accuracy: 0.8380\n",
            "Epoch 41/120\n",
            "40/40 [==============================] - 5s 120ms/step - loss: 0.2406 - accuracy: 0.8915 - val_loss: 0.4652 - val_accuracy: 0.8170\n",
            "Epoch 42/120\n",
            "40/40 [==============================] - 5s 129ms/step - loss: 0.2375 - accuracy: 0.8960 - val_loss: 0.4078 - val_accuracy: 0.8410\n",
            "Epoch 43/120\n",
            "40/40 [==============================] - 5s 128ms/step - loss: 0.2337 - accuracy: 0.8967 - val_loss: 0.3971 - val_accuracy: 0.8530\n",
            "Epoch 44/120\n",
            "40/40 [==============================] - 5s 128ms/step - loss: 0.2169 - accuracy: 0.9047 - val_loss: 0.4001 - val_accuracy: 0.8460\n",
            "Epoch 45/120\n",
            "40/40 [==============================] - 6s 135ms/step - loss: 0.1981 - accuracy: 0.9134 - val_loss: 0.3445 - val_accuracy: 0.8610\n",
            "Epoch 46/120\n",
            "40/40 [==============================] - 5s 119ms/step - loss: 0.1804 - accuracy: 0.9238 - val_loss: 0.3003 - val_accuracy: 0.8810\n",
            "Epoch 47/120\n",
            "40/40 [==============================] - 5s 122ms/step - loss: 0.1706 - accuracy: 0.9303 - val_loss: 0.2707 - val_accuracy: 0.8840\n",
            "Epoch 48/120\n",
            "40/40 [==============================] - 5s 121ms/step - loss: 0.1521 - accuracy: 0.9378 - val_loss: 0.2694 - val_accuracy: 0.8970\n",
            "Epoch 49/120\n",
            "40/40 [==============================] - 5s 127ms/step - loss: 0.1430 - accuracy: 0.9412 - val_loss: 0.2570 - val_accuracy: 0.8990\n",
            "Epoch 50/120\n",
            "40/40 [==============================] - 7s 167ms/step - loss: 0.1395 - accuracy: 0.9410 - val_loss: 0.2277 - val_accuracy: 0.8970\n",
            "Epoch 51/120\n",
            "40/40 [==============================] - 6s 142ms/step - loss: 0.1348 - accuracy: 0.9453 - val_loss: 0.2819 - val_accuracy: 0.8950\n",
            "Epoch 52/120\n",
            "40/40 [==============================] - 6s 150ms/step - loss: 0.1301 - accuracy: 0.9461 - val_loss: 0.2664 - val_accuracy: 0.9010\n",
            "Epoch 53/120\n",
            "40/40 [==============================] - 5s 126ms/step - loss: 0.1251 - accuracy: 0.9475 - val_loss: 0.2830 - val_accuracy: 0.8940\n",
            "Epoch 54/120\n",
            "40/40 [==============================] - 5s 123ms/step - loss: 0.1245 - accuracy: 0.9482 - val_loss: 0.2561 - val_accuracy: 0.9050\n",
            "Epoch 55/120\n",
            "40/40 [==============================] - 5s 123ms/step - loss: 0.1318 - accuracy: 0.9466 - val_loss: 0.2532 - val_accuracy: 0.8980\n",
            "Epoch 56/120\n",
            "40/40 [==============================] - 5s 135ms/step - loss: 0.1188 - accuracy: 0.9519 - val_loss: 0.3408 - val_accuracy: 0.8940\n",
            "Epoch 57/120\n",
            "40/40 [==============================] - 6s 153ms/step - loss: 0.1163 - accuracy: 0.9533 - val_loss: 0.2442 - val_accuracy: 0.8960\n",
            "Epoch 58/120\n",
            "40/40 [==============================] - 5s 126ms/step - loss: 0.1128 - accuracy: 0.9533 - val_loss: 0.2447 - val_accuracy: 0.9050\n",
            "Epoch 59/120\n",
            "40/40 [==============================] - 6s 154ms/step - loss: 0.1084 - accuracy: 0.9560 - val_loss: 0.2443 - val_accuracy: 0.8930\n",
            "Epoch 60/120\n",
            "40/40 [==============================] - 5s 124ms/step - loss: 0.1073 - accuracy: 0.9573 - val_loss: 0.2583 - val_accuracy: 0.9080\n",
            "Epoch 61/120\n",
            "40/40 [==============================] - 5s 128ms/step - loss: 0.1010 - accuracy: 0.9584 - val_loss: 0.2511 - val_accuracy: 0.9060\n",
            "Epoch 62/120\n",
            "40/40 [==============================] - 5s 125ms/step - loss: 0.0979 - accuracy: 0.9590 - val_loss: 0.2611 - val_accuracy: 0.9040\n",
            "Epoch 63/120\n",
            "40/40 [==============================] - 5s 130ms/step - loss: 0.0952 - accuracy: 0.9636 - val_loss: 0.2444 - val_accuracy: 0.9150\n",
            "Epoch 64/120\n",
            "40/40 [==============================] - 5s 128ms/step - loss: 0.0958 - accuracy: 0.9598 - val_loss: 0.2350 - val_accuracy: 0.9100\n",
            "Epoch 65/120\n",
            "40/40 [==============================] - 5s 131ms/step - loss: 0.0945 - accuracy: 0.9619 - val_loss: 0.2265 - val_accuracy: 0.9220\n",
            "Epoch 66/120\n",
            "40/40 [==============================] - 5s 130ms/step - loss: 0.0881 - accuracy: 0.9666 - val_loss: 0.2083 - val_accuracy: 0.9280\n",
            "Epoch 67/120\n",
            "40/40 [==============================] - 5s 121ms/step - loss: 0.0873 - accuracy: 0.9667 - val_loss: 0.2872 - val_accuracy: 0.9220\n",
            "Epoch 68/120\n",
            "40/40 [==============================] - 5s 126ms/step - loss: 0.0792 - accuracy: 0.9694 - val_loss: 0.2855 - val_accuracy: 0.9210\n",
            "Epoch 69/120\n",
            "40/40 [==============================] - 5s 129ms/step - loss: 0.0840 - accuracy: 0.9689 - val_loss: 0.2135 - val_accuracy: 0.9330\n",
            "Epoch 70/120\n",
            "40/40 [==============================] - 6s 141ms/step - loss: 0.0710 - accuracy: 0.9726 - val_loss: 0.2103 - val_accuracy: 0.9330\n",
            "Epoch 71/120\n",
            "40/40 [==============================] - 5s 121ms/step - loss: 0.0763 - accuracy: 0.9710 - val_loss: 0.1991 - val_accuracy: 0.9360\n",
            "Epoch 72/120\n",
            "40/40 [==============================] - 5s 116ms/step - loss: 0.0707 - accuracy: 0.9719 - val_loss: 0.2479 - val_accuracy: 0.9310\n",
            "Epoch 73/120\n",
            "40/40 [==============================] - 5s 126ms/step - loss: 0.0777 - accuracy: 0.9715 - val_loss: 0.2028 - val_accuracy: 0.9340\n",
            "Epoch 74/120\n",
            "40/40 [==============================] - 5s 134ms/step - loss: 0.0733 - accuracy: 0.9725 - val_loss: 0.1944 - val_accuracy: 0.9370\n",
            "Epoch 75/120\n",
            "40/40 [==============================] - 5s 125ms/step - loss: 0.0685 - accuracy: 0.9745 - val_loss: 0.2220 - val_accuracy: 0.9250\n",
            "Epoch 76/120\n",
            "40/40 [==============================] - 5s 129ms/step - loss: 0.0672 - accuracy: 0.9750 - val_loss: 0.2190 - val_accuracy: 0.9350\n",
            "Epoch 77/120\n",
            "40/40 [==============================] - 5s 126ms/step - loss: 0.0672 - accuracy: 0.9754 - val_loss: 0.1891 - val_accuracy: 0.9330\n",
            "Epoch 78/120\n",
            "40/40 [==============================] - 5s 127ms/step - loss: 0.0662 - accuracy: 0.9745 - val_loss: 0.1970 - val_accuracy: 0.9440\n",
            "Epoch 79/120\n",
            "40/40 [==============================] - 5s 121ms/step - loss: 0.0630 - accuracy: 0.9772 - val_loss: 0.1714 - val_accuracy: 0.9400\n",
            "Epoch 80/120\n",
            "40/40 [==============================] - 5s 130ms/step - loss: 0.0730 - accuracy: 0.9745 - val_loss: 0.1964 - val_accuracy: 0.9340\n",
            "Epoch 81/120\n",
            "40/40 [==============================] - 5s 133ms/step - loss: 0.0618 - accuracy: 0.9757 - val_loss: 0.2095 - val_accuracy: 0.9310\n",
            "Epoch 82/120\n",
            "40/40 [==============================] - 5s 134ms/step - loss: 0.0596 - accuracy: 0.9759 - val_loss: 0.2007 - val_accuracy: 0.9380\n",
            "Epoch 83/120\n",
            "40/40 [==============================] - 5s 121ms/step - loss: 0.0629 - accuracy: 0.9763 - val_loss: 0.2088 - val_accuracy: 0.9280\n",
            "Epoch 84/120\n",
            "40/40 [==============================] - 5s 128ms/step - loss: 0.0574 - accuracy: 0.9776 - val_loss: 0.2607 - val_accuracy: 0.9140\n",
            "Epoch 85/120\n",
            "40/40 [==============================] - 5s 126ms/step - loss: 0.0592 - accuracy: 0.9785 - val_loss: 0.1957 - val_accuracy: 0.9430\n",
            "Epoch 86/120\n",
            "40/40 [==============================] - 5s 136ms/step - loss: 0.0578 - accuracy: 0.9784 - val_loss: 0.1874 - val_accuracy: 0.9410\n",
            "Epoch 87/120\n",
            "40/40 [==============================] - 5s 129ms/step - loss: 0.0539 - accuracy: 0.9802 - val_loss: 0.2108 - val_accuracy: 0.9400\n",
            "Epoch 88/120\n",
            "40/40 [==============================] - 5s 128ms/step - loss: 0.0523 - accuracy: 0.9809 - val_loss: 0.1734 - val_accuracy: 0.9420\n",
            "Epoch 89/120\n",
            "40/40 [==============================] - 5s 116ms/step - loss: 0.0546 - accuracy: 0.9804 - val_loss: 0.1939 - val_accuracy: 0.9420\n",
            "Epoch 90/120\n",
            "40/40 [==============================] - 5s 118ms/step - loss: 0.0561 - accuracy: 0.9787 - val_loss: 0.2389 - val_accuracy: 0.9180\n",
            "Epoch 91/120\n",
            "40/40 [==============================] - 5s 135ms/step - loss: 0.0584 - accuracy: 0.9802 - val_loss: 0.1724 - val_accuracy: 0.9440\n",
            "Epoch 92/120\n",
            "40/40 [==============================] - 5s 128ms/step - loss: 0.0519 - accuracy: 0.9795 - val_loss: 0.1944 - val_accuracy: 0.9420\n",
            "Epoch 93/120\n",
            "40/40 [==============================] - 5s 130ms/step - loss: 0.0547 - accuracy: 0.9793 - val_loss: 0.2387 - val_accuracy: 0.9340\n",
            "Epoch 94/120\n",
            "40/40 [==============================] - 5s 126ms/step - loss: 0.0528 - accuracy: 0.9822 - val_loss: 0.2115 - val_accuracy: 0.9290\n",
            "Epoch 95/120\n",
            "40/40 [==============================] - 5s 130ms/step - loss: 0.0552 - accuracy: 0.9798 - val_loss: 0.1725 - val_accuracy: 0.9440\n",
            "Epoch 96/120\n",
            "40/40 [==============================] - 5s 128ms/step - loss: 0.0465 - accuracy: 0.9829 - val_loss: 0.2104 - val_accuracy: 0.9450\n",
            "Epoch 97/120\n",
            "40/40 [==============================] - 6s 151ms/step - loss: 0.0494 - accuracy: 0.9835 - val_loss: 0.1966 - val_accuracy: 0.9430\n",
            "Epoch 98/120\n",
            "40/40 [==============================] - 6s 141ms/step - loss: 0.0508 - accuracy: 0.9822 - val_loss: 0.2068 - val_accuracy: 0.9390\n",
            "Epoch 99/120\n",
            "40/40 [==============================] - 5s 129ms/step - loss: 0.0523 - accuracy: 0.9818 - val_loss: 0.1758 - val_accuracy: 0.9410\n",
            "Epoch 100/120\n",
            "40/40 [==============================] - 6s 147ms/step - loss: 0.0443 - accuracy: 0.9839 - val_loss: 0.2056 - val_accuracy: 0.9450\n",
            "Epoch 101/120\n",
            "40/40 [==============================] - 5s 126ms/step - loss: 0.0500 - accuracy: 0.9823 - val_loss: 0.1903 - val_accuracy: 0.9470\n",
            "Epoch 102/120\n",
            "40/40 [==============================] - 6s 139ms/step - loss: 0.0548 - accuracy: 0.9813 - val_loss: 0.2473 - val_accuracy: 0.9330\n",
            "Epoch 103/120\n",
            "40/40 [==============================] - 5s 134ms/step - loss: 0.0435 - accuracy: 0.9840 - val_loss: 0.2226 - val_accuracy: 0.9410\n",
            "Epoch 104/120\n",
            "40/40 [==============================] - 5s 129ms/step - loss: 0.0469 - accuracy: 0.9824 - val_loss: 0.1989 - val_accuracy: 0.9390\n",
            "Epoch 105/120\n",
            "40/40 [==============================] - 6s 149ms/step - loss: 0.0449 - accuracy: 0.9848 - val_loss: 0.1993 - val_accuracy: 0.9440\n",
            "Epoch 106/120\n",
            "40/40 [==============================] - 7s 162ms/step - loss: 0.0428 - accuracy: 0.9829 - val_loss: 0.2388 - val_accuracy: 0.9410\n",
            "Epoch 107/120\n",
            "40/40 [==============================] - 5s 122ms/step - loss: 0.0425 - accuracy: 0.9845 - val_loss: 0.2228 - val_accuracy: 0.9400\n",
            "Epoch 108/120\n",
            "40/40 [==============================] - 5s 137ms/step - loss: 0.0407 - accuracy: 0.9852 - val_loss: 0.2133 - val_accuracy: 0.9410\n",
            "Epoch 109/120\n",
            "40/40 [==============================] - 5s 125ms/step - loss: 0.0493 - accuracy: 0.9829 - val_loss: 0.2280 - val_accuracy: 0.9430\n",
            "Epoch 110/120\n",
            "40/40 [==============================] - 5s 130ms/step - loss: 0.0395 - accuracy: 0.9861 - val_loss: 0.2727 - val_accuracy: 0.9430\n",
            "Epoch 111/120\n",
            "40/40 [==============================] - 5s 128ms/step - loss: 0.0460 - accuracy: 0.9841 - val_loss: 0.2092 - val_accuracy: 0.9400\n",
            "Epoch 112/120\n",
            "40/40 [==============================] - 5s 130ms/step - loss: 0.0406 - accuracy: 0.9854 - val_loss: 0.2036 - val_accuracy: 0.9430\n",
            "Epoch 113/120\n",
            "40/40 [==============================] - 5s 125ms/step - loss: 0.0452 - accuracy: 0.9843 - val_loss: 0.1966 - val_accuracy: 0.9470\n",
            "Epoch 114/120\n",
            "40/40 [==============================] - 5s 117ms/step - loss: 0.0419 - accuracy: 0.9857 - val_loss: 0.1900 - val_accuracy: 0.9420\n",
            "Epoch 115/120\n",
            "40/40 [==============================] - 5s 136ms/step - loss: 0.0409 - accuracy: 0.9863 - val_loss: 0.2110 - val_accuracy: 0.9420\n",
            "Epoch 116/120\n",
            "40/40 [==============================] - 5s 124ms/step - loss: 0.0438 - accuracy: 0.9849 - val_loss: 0.1802 - val_accuracy: 0.9420\n",
            "Epoch 117/120\n",
            "40/40 [==============================] - 5s 129ms/step - loss: 0.0402 - accuracy: 0.9853 - val_loss: 0.2056 - val_accuracy: 0.9430\n",
            "Epoch 118/120\n",
            "40/40 [==============================] - 7s 170ms/step - loss: 0.0376 - accuracy: 0.9870 - val_loss: 0.1863 - val_accuracy: 0.9420\n",
            "Epoch 119/120\n",
            "40/40 [==============================] - 5s 124ms/step - loss: 0.0471 - accuracy: 0.9849 - val_loss: 0.2489 - val_accuracy: 0.9420\n",
            "Epoch 120/120\n",
            "40/40 [==============================] - 5s 129ms/step - loss: 0.0392 - accuracy: 0.9856 - val_loss: 0.1923 - val_accuracy: 0.9500\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Saving the Model**"
      ],
      "metadata": {
        "id": "DvDwVGCYFs9T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "filename = 'chatbot_120_epochs_9710.h5'\n",
        "model.save(filename)"
      ],
      "metadata": {
        "id": "4n39LCYvEtzt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Evaluating the Model**"
      ],
      "metadata": {
        "id": "S7kk2Y_VFyzh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Plotting Out Training History**"
      ],
      "metadata": {
        "id": "Vm4fXQvYF56G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "print(history.history.keys())\n",
        "# summarize history for accuracy\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.savefig('accuracy.png', dpi=180, facecolor='white')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        },
        "id": "8X2UtdI-EwLx",
        "outputId": "050abe2b-6026-46a5-ead6-136d521a1e80"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Evaluating on Given Test Set**"
      ],
      "metadata": {
        "id": "gAfn-V46GCml"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#model.load_weights(filename)\n",
        "pred_results = model.predict(([inputs_test, queries_test]))"
      ],
      "metadata": {
        "id": "OmEcwK6xFXcD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_data[0][0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6WAzklJLFdqw",
        "outputId": "7692af53-5895-4f95-f74e-5cb9d938827b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Mary',\n",
              " 'got',\n",
              " 'the',\n",
              " 'milk',\n",
              " 'there',\n",
              " '.',\n",
              " 'John',\n",
              " 'moved',\n",
              " 'to',\n",
              " 'the',\n",
              " 'bedroom',\n",
              " '.']"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "story =' '.join(word for word in test_data[0][0])\n",
        "print(story)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8kxCV7fAFhDB",
        "outputId": "9e2d2b24-da9f-463e-83bd-489bfffa95a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mary got the milk there . John moved to the bedroom .\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query = ' '.join(word for word in test_data[0][1])\n",
        "print(query)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "byiYtrZ3Fmp5",
        "outputId": "91773a1e-c6eb-4449-d62b-f1b0c9bf2006"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Is John in the kitchen ?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"True Test Answer from Data is:\",test_data[0][2])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jdbf8J9PFp4n",
        "outputId": "7a2ab8b4-da3e-44a9-9d8b-104755d40ad5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True Test Answer from Data is: no\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Generate prediction from model\n",
        "val_max = np.argmax(pred_results[0])\n",
        "\n",
        "for key, val in tokenizer.word_index.items():\n",
        "    if val == val_max:\n",
        "        k = key\n",
        "\n",
        "print(\"Predicted answer is: \", k)\n",
        "print(\"Probability of certainty was: \", pred_results[0][val_max])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-sp-MvFjFvE7",
        "outputId": "e74b150d-b9b8-4335-fc02-ccacc3f4c93a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted answer is:  no\n",
            "Probability of certainty was:  1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Writing Your Own Stories and Questions**"
      ],
      "metadata": {
        "id": "jyiSvZJ_GjB8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Remember you can only use words from the existing vocab"
      ],
      "metadata": {
        "id": "Vo3FDnpmGo2y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vocab"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WdNULIpJF8CI",
        "outputId": "a89f10f5-896f-48ac-8e06-b8196e2fc5a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'.',\n",
              " '?',\n",
              " 'Daniel',\n",
              " 'Is',\n",
              " 'John',\n",
              " 'Mary',\n",
              " 'Sandra',\n",
              " 'apple',\n",
              " 'back',\n",
              " 'bathroom',\n",
              " 'bedroom',\n",
              " 'discarded',\n",
              " 'down',\n",
              " 'dropped',\n",
              " 'football',\n",
              " 'garden',\n",
              " 'got',\n",
              " 'grabbed',\n",
              " 'hallway',\n",
              " 'in',\n",
              " 'journeyed',\n",
              " 'kitchen',\n",
              " 'left',\n",
              " 'milk',\n",
              " 'moved',\n",
              " 'no',\n",
              " 'office',\n",
              " 'picked',\n",
              " 'put',\n",
              " 'the',\n",
              " 'there',\n",
              " 'to',\n",
              " 'took',\n",
              " 'travelled',\n",
              " 'up',\n",
              " 'went',\n",
              " 'yes'}"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Note the whitespace of the periods\n",
        "my_story = \"John left the kitchen . Sandra dropped the football in the garden .\"\n",
        "my_story.split()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3tFwT5ASF9yk",
        "outputId": "a3b01fab-7984-4a9a-f8b4-68621da8aa59"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['John',\n",
              " 'left',\n",
              " 'the',\n",
              " 'kitchen',\n",
              " '.',\n",
              " 'Sandra',\n",
              " 'dropped',\n",
              " 'the',\n",
              " 'football',\n",
              " 'in',\n",
              " 'the',\n",
              " 'garden',\n",
              " '.']"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "my_question = \"Is the football in the garden ?\""
      ],
      "metadata": {
        "id": "ydpmNIPEGDQT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "my_question.split()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JzpZMNIyGRDe",
        "outputId": "c8e8979e-4bde-44da-cf2c-7a9eb71f2e63"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Is', 'the', 'football', 'in', 'the', 'garden', '?']"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mydata = [(my_story.split(),my_question.split(),'yes')]"
      ],
      "metadata": {
        "id": "yKutAMY3GUtA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "my_story,my_ques,my_ans = vectorize_stories(mydata)"
      ],
      "metadata": {
        "id": "hK0Et7ZTGYdX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred_results = model.predict(([ my_story, my_ques]))"
      ],
      "metadata": {
        "id": "Ri3JoSLbGcjX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Generate prediction from model\n",
        "val_max = np.argmax(pred_results[0])\n",
        "\n",
        "for key, val in tokenizer.word_index.items():\n",
        "    if val == val_max:\n",
        "        k = key\n",
        "\n",
        "print(\"Predicted answer is: \", k)\n",
        "print(\"Probability of certainty was: \", pred_results[0][val_max])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kN9Zz0ZmGnwV",
        "outputId": "0b1d9b1e-85bd-4920-9a07-9f8223cf4cce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted answer is:  yes\n",
            "Probability of certainty was:  0.9981152\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **test**"
      ],
      "metadata": {
        "id": "FXlVFTQWGzJe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "my_story = \"Sandra grabbed Mary in the kitchen . Sandra picked the apple in the garden . John got back in the office . Mary got the milk . Daniel discarded the apple .\"\n",
        "my_question = \"Is apple in the garden ?\"\n",
        "mydata = [(my_story.split(),my_question.split(),'yes')]\n",
        "my_story,my_ques,my_ans = vectorize_stories(mydata)"
      ],
      "metadata": {
        "id": "foYHskrCGsiO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred_results = model.predict(([ my_story, my_ques]))"
      ],
      "metadata": {
        "id": "QJqVeCu9Gwzy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Generate prediction from model\n",
        "val_max = np.argmax(pred_results[0])\n",
        "\n",
        "for key, val in tokenizer.word_index.items():\n",
        "    if val == val_max:\n",
        "        k = key\n",
        "\n",
        "print(\"Predicted answer is: \", k)\n",
        "print(\"Probability of certainty was: \", pred_results[0][val_max])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QL9np-FTG2yK",
        "outputId": "43124aa3-7e78-466d-9386-4d8bbf5ec2f7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted answer is:  yes\n",
            "Probability of certainty was:  0.9968484\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "my_story = 'Daniel grabbed the apple there . Daniel went to the bedroom . John moved to the garden . Sandra journeyed to the office . Daniel put down the apple . Mary went to the bedroom . Mary grabbed the apple there . Sandra went back to the garden . Mary went to the kitchen . Daniel went to the office .'\n",
        "my_question = \"Is Mary in the kitchen ?\"\n",
        "mydata = [(my_story.split(),my_question.split(),'yes')]\n",
        "my_story,my_ques,my_ans = vectorize_stories(mydata)"
      ],
      "metadata": {
        "id": "KDIME6_hG6Zt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred_results = model.predict(([ my_story, my_ques]))"
      ],
      "metadata": {
        "id": "iHdwV-VZHImK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Generate prediction from model\n",
        "val_max = np.argmax(pred_results[0])\n",
        "\n",
        "for key, val in tokenizer.word_index.items():\n",
        "    if val == val_max:\n",
        "        k = key\n",
        "\n",
        "print(\"Predicted answer is: \", k)\n",
        "print(\"Probability of certainty was: \", pred_results[0][val_max])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QR5Wcb_XHUSQ",
        "outputId": "d23bb74c-e550-4ffa-bca6-2418e0b77271"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted answer is:  yes\n",
            "Probability of certainty was:  0.99984264\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "my_story = 'Daniel grabbed the apple there . Daniel went to the bedroom . John moved to the garden . Sandra journeyed to the office . Daniel put down the apple . Mary went to the bedroom . Mary grabbed the apple there . Sandra went back to the garden . Mary went to the kitchen . Daniel went to the office .'\n",
        "my_question = \"Is Mary in the bedroom ?\"\n",
        "mydata = [(my_story.split(),my_question.split(),'no')]\n",
        "my_story,my_ques,my_ans = vectorize_stories(mydata)"
      ],
      "metadata": {
        "id": "f2TE9pT7HXvE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred_results = model.predict(([ my_story, my_ques]))"
      ],
      "metadata": {
        "id": "wBkWewS6Hcxj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Generate prediction from model\n",
        "val_max = np.argmax(pred_results[0])\n",
        "\n",
        "for key, val in tokenizer.word_index.items():\n",
        "    if val == val_max:\n",
        "        k = key\n",
        "\n",
        "print(\"Predicted answer is: \", k)\n",
        "print(\"Probability of certainty was: \", pred_results[0][val_max])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Zhb-4QOHgeG",
        "outputId": "858d9d23-f18a-4c0b-8e6f-4a729c4c9de4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted answer is:  no\n",
            "Probability of certainty was:  0.9946989\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Conclusion**"
      ],
      "metadata": {
        "id": "tgYtyCglVP3x"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this we can get the results as The model is trained very quickly over 120 epochs using RMSprop and lr = 0.01. Other hyperparameters: Embedding size of 128, batch size of 256. Accuracy on unseen test data reaches over 97%.Hence We get accurate results of  extracting an answer from a text given a question. The\n",
        "text would essentially be the group of documents that have the highest concentration of the topic closest to the asked question."
      ],
      "metadata": {
        "id": "XEFOT-RdVnY3"
      }
    }
  ]
}